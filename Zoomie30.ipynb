{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import shutil\n",
    "\n",
    "def create_data_frame_form_folder(folder_path:str)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataframe with all image names\n",
    "    Args:\n",
    "        folder_path:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    full_file_name =[]\n",
    "    date_l = []\n",
    "    time_l =[]\n",
    "    ms_l =[]\n",
    "    imgnr_l=[]\n",
    "    y_coord_l =[]\n",
    "    x_coord_l =[]\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for name in files:\n",
    "            if name.endswith('.png'):\n",
    "                full_file_name.append(name)\n",
    "                name_split = name.split(\" \")\n",
    "                date_l.append(name_split[0])\n",
    "                time_l.append(name_split[1])\n",
    "                ms_l.append(name_split[3])\n",
    "                imgnr_l.append(name_split[5])\n",
    "                y_coord_l.append(name_split[6])\n",
    "                x_coord_l.append(name_split[7].split(\".\")[0])\n",
    "    df[\"date\"] =date_l\n",
    "    df[\"time\"]=time_l\n",
    "    df[\"ms\"]=ms_l\n",
    "    df[\"imgnr\"]=imgnr_l\n",
    "    df[\"y-coord\"]=y_coord_l\n",
    "    df[\"x-coord\"]=x_coord_l\n",
    "    df[\"filename\"] = full_file_name\n",
    "    df[\"path\"] = folder_path\n",
    "    df[\"ms\"] =df[\"ms\"].astype('int')\n",
    "    df['x-coord'] =df['x-coord'].astype('int')\n",
    "    df['y-coord'] =df['y-coord'].astype('int')\n",
    "    df = df.sort_values([\"date\",\"time\",\"ms\"]).copy()\n",
    "    df[\"date_time\"] =df[\"date\"].astype('str')+df[\"time\"].astype('str')\n",
    "    print(df.shape)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = create_data_frame_form_folder(\"data/5_cruises/PS99.2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sort =df.sort_values(by=[\"date\",\"time\",\"ms\",\"imgnr\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sort"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sort.max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sort.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##\n",
    "import pandas as pd\n",
    "theta, alpha, beta = (60,2000,2000)\n",
    "# Step 2: Read data into a DataFrame (assuming your DataFrame is named 'df')\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Step 3: Create a function to check for duplicates\n",
    "def are_duplicates(img1, img2, theta, alpha, beta):\n",
    "    if (img2['ms'] - img1['ms'] < theta and\n",
    "            img2['x-coord'] - img1['x-coord'] < alpha and\n",
    "            img2['y-coord'] - img1['y-coord'] < beta):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Step 4: Group the DataFrame by ['date', 'time', 'ms']\n",
    "grouped = df_sort.groupby(['date', 'time', 'ms'])\n",
    "\n",
    "# Step 5: Iterate over each group to find duplicates and update the 'filename' column\n",
    "duplicates = {}\n",
    "for _, group in grouped:\n",
    "    filenames = list(group['filename'])\n",
    "    updated_filenames = []\n",
    "    for filename in filenames:\n",
    "        img1 = group[group['filename'] == filename].iloc[0]  # Take the first image with the same filename\n",
    "        duplicates[filename] = [filename]  # Add itself to the duplicates list\n",
    "        for _, img2 in group.iterrows():\n",
    "            if img1['filename'] != img2['filename'] and are_duplicates(img1, img2, theta, alpha, beta):\n",
    "                duplicates[filename].append(img2['filename'])\n",
    "                duplicates[filename].sort()\n",
    "# Step 6: Create a new DataFrame with the updated 'filename' column and count of duplicates\n",
    "df_duplicates = pd.DataFrame({'filename': list(duplicates.keys()), 'duplicates': list(duplicates.values())})\n",
    "\n",
    "# Add a new column 'dub' containing the number of duplicates found\n",
    "df_duplicates['dub'] = df_duplicates['duplicates'].apply(lambda x: len(x) - 1)\n",
    "\n",
    "# Create a dictionary to map filenames to 'keep' values\n",
    "keep_map = {}\n",
    "for _, row in df_duplicates.iterrows():\n",
    "    duplicates_list = row['duplicates']\n",
    "    filename = row['filename']\n",
    "    if len(duplicates_list) == 1:\n",
    "        keep_map[filename] = 1\n",
    "    else:\n",
    "        if filename != duplicates_list[0]:\n",
    "            keep_map[filename] = 0\n",
    "        else:\n",
    "            keep_map[filename] = 1\n",
    "\n",
    "# Add the 'keep' column to the original DataFrame\n",
    "merged_df4 = pd.merge(df_sort, df_duplicates, on='filename', how='left')\n",
    "merged_df4['keep'] = merged_df4['filename'].map(keep_map).fillna(1)\n",
    "\n",
    "# Print the merged DataFrame to see the result\n",
    "print(merged_df4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df4[\"keep\"].sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df4.to_csv(\"barbara/zooomieeee.csv\", sep=\";\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"output/update_allcruises_df_validated_5with_zoomie_20230727.csv\",sep=\";\")\n",
    "df_all = df_all[df_all['object_cruise']==\"PS99.2\"]\n",
    "df_artefacts = df_all[df_all[\"label\"] == \"Artefact\"]\n",
    "df_artefacts.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nic = set(df_artefacts[\"img_file_name\"].tolist())\n",
    "len(nic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doubles = set(merged_df4[merged_df4[\"keep\"]==0][\"filename\"].tolist())\n",
    "def flatten_list(input_list):\n",
    "    return sum(input_list, [])\n",
    "doubles2 = set(flatten_list((merged_df4[merged_df4[\"dub\"]!=0][\"duplicates\"].tolist())))\n",
    "print(len(doubles))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(nic.difference(doubles))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(doubles.difference(nic))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(nic.intersection(doubles))/len(nic)*100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "# Example lists\n",
    "list1 = doubles\n",
    "list2 = doubles2\n",
    "list3 = nic\n",
    "\n",
    "# Convert lists to sets for Venn diagram\n",
    "set1 = set(list1)\n",
    "set2 = set(list2)\n",
    "set3 = set(list3)\n",
    "\n",
    "# Calculate the sizes of the exclusive areas\n",
    "list1_exclusive_size = len(set1.difference(set2.union(set3)))\n",
    "list2_exclusive_size = len(set2.difference(set1.union(set3)))\n",
    "list3_exclusive_size = len(set3.difference(set1.union(set2)))\n",
    "\n",
    "# Calculate the sizes of the intersection areas\n",
    "intersection12_size = len(set1.intersection(set2))\n",
    "intersection13_size = len(set1.intersection(set3))\n",
    "intersection23_size = len(set2.intersection(set3))\n",
    "intersection123_size = len(set1.intersection(set2, set3))\n",
    "\n",
    "# Calculate the total size for percentage calculation\n",
    "total_size = len(set1.union(set2, set3))\n",
    "\n",
    "# Create a new figure with a specific size\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a Venn diagram\n",
    "venn_diagram = venn3(subsets=(list1_exclusive_size, list2_exclusive_size, intersection12_size,\n",
    "                              list3_exclusive_size, intersection13_size, intersection23_size,\n",
    "                              intersection123_size),\n",
    "                     set_labels=(f'Duplicates (keep first) {len(set1)}', f'Duplicates (all) {len(set2)}', f'Ground truth {len(set3)}'))\n",
    "\n",
    "# Customize the Venn diagram (if desired)\n",
    "venn_diagram.get_label_by_id('100').set_text(\n",
    "    f'Only Duplicates (keep first): {list1_exclusive_size}')\n",
    "venn_diagram.get_label_by_id('010').set_text(\n",
    "    f'Only Duplicates (all): {list2_exclusive_size}')\n",
    "venn_diagram.get_label_by_id('001').set_text(\n",
    "    f'Only Ground truth: {list3_exclusive_size} ')\n",
    "venn_diagram.get_label_by_id('110').set_text(\n",
    "    f'Overlap (keep first) (all): {intersection12_size} ')\n",
    "venn_diagram.get_label_by_id('101').set_text(\n",
    "    f'Overlap (keep first) Ground truth: {intersection13_size} ({(intersection13_size / len(set(nic))) * 100:.1f}%)')\n",
    "venn_diagram.get_label_by_id('011').set_text(\n",
    "    f'Overlap (all) Ground truth: {intersection23_size} ({(intersection23_size / len(set(nic))) * 100:.1f}%)')\n",
    "venn_diagram.get_label_by_id('111').set_text(\n",
    "    f'Overlap ALL: {intersection123_size} ({(intersection123_size / len(set(nic))) * 100:.1f}%)')\n",
    "\n",
    "# Save the plot as an image file (e.g., PNG format)\n",
    "#plt.title(\"Venn Diagram of Duplicates (keep first), Duplicates (all), and Nicole - for the % with (Ground truth is Base)\")\n",
    "plt.savefig(\"barbara/Ground truth_venn_diagram_3_class_diff_60_2000_2000.png\")\n",
    "\n",
    "# Show the plot (optional)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
